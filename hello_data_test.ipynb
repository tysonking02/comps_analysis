{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "api_key = \"f3898958-b76a-4a47-816f-0294f0c5103d\"\n",
    "\n",
    "BASE_URL = \"https://api.hellodata.ai\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"x-api-key\": api_key\n",
    "}\n",
    "\n",
    "dimasset = pd.read_csv('data/DimAsset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_lon(property):\n",
    "    \"\"\"Function to get latitude and longitude for a given property.\"\"\"\n",
    "    matches = dimasset[dimasset['AssetName'].str.contains(property, case=False, regex=False)].dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "    if matches.empty:\n",
    "        raise ValueError(f\"No match found for property: {property}\")\n",
    "\n",
    "    lat, lon = matches[['Latitude', 'Longitude']].iloc[0]\n",
    "\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        raise ValueError(f\"Latitude or Longitude missing for property: {property}\")\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "def fetch_property_data(property, lat=None, lon=None, zip_code=None):\n",
    "    \"\"\"Function to fetch property data using the provided latitude and longitude.\n",
    "       If lat and lon are not provided, they are omitted from the query.\"\"\"\n",
    "    \n",
    "    encoded_property_name = property\n",
    "    \n",
    "    # Create the querystring dictionary\n",
    "    querystring = {\"q\": encoded_property_name}\n",
    "    \n",
    "    # Only add lat and lon if they are provided\n",
    "    if lat is not None and lon is not None:\n",
    "        querystring[\"lat\"] = lat\n",
    "        querystring[\"lon\"] = lon\n",
    "        querystring[\"max_distance\"] = 0.1\n",
    "\n",
    "    if zip_code is not None:\n",
    "        querystring['zip_code'] = zip_code\n",
    "    \n",
    "    # Make the API request\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/property/search\", headers=HEADERS, params=querystring)\n",
    "        response.raise_for_status()  # Raise HTTP errors (e.g., 404, 500)\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"HTTP request error: {e}\")\n",
    "        return None\n",
    "    except ValueError:\n",
    "        print(\"Error parsing JSON response from property search.\")\n",
    "        return None\n",
    "\n",
    "def fetch_property_details(property_id):\n",
    "    \"\"\"Function to fetch details for a specific property.\"\"\"\n",
    "    url = f\"{BASE_URL}/property/{property_id}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"HTTP request error while fetching property details: {e}\")\n",
    "        return None\n",
    "    except ValueError:\n",
    "        print(\"Error parsing JSON response from property details.\")\n",
    "        return None\n",
    "\n",
    "def fetch_comparables(property_details):\n",
    "    \"\"\"Function to fetch comparables for a given property.\"\"\"\n",
    "    url = f\"{BASE_URL}/property/comparables\"\n",
    "    payload = {\"subject\": property_details}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"HTTP request error while fetching comparables: {e}\")\n",
    "        return None\n",
    "    except ValueError:\n",
    "        print(\"Error parsing JSON response from comparables.\")\n",
    "        return None\n",
    "\n",
    "def get_comps(property):\n",
    "    \"\"\"Final function to get the comparables data for a property.\"\"\"\n",
    "    try:\n",
    "        lat, lon = get_lat_lon(property)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in get_lat_lon: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Fetch property data\n",
    "    property_data = fetch_property_data(property, lat, lon)\n",
    "    if not property_data or not isinstance(property_data, list):\n",
    "        print(f\"Unexpected response format from property search: {property_data}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        property_id = property_data[0].get(\"id\")\n",
    "        if not property_id:\n",
    "            raise KeyError(\"Missing 'id' in property response.\")\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(f\"Error extracting property ID: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Fetch property details\n",
    "    property_details = fetch_property_details(property_id)\n",
    "    if not property_details:\n",
    "        return None\n",
    "\n",
    "    # Fetch comparables\n",
    "    response_data = fetch_comparables(property_details)\n",
    "    if not response_data or 'comparables' not in response_data or not isinstance(response_data['comparables'], list):\n",
    "        print(f\"Unexpected response format for comparables: {response_data}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        comps = pd.json_normalize(response_data['comparables'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error normalizing comparables data: {e}\")\n",
    "        return None\n",
    "\n",
    "    return comps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit_history(property_details):\n",
    "    try:\n",
    "        if not isinstance(property_details, dict):\n",
    "            raise TypeError(f\"Expected dictionary for property_details, got {type(property_details)}\")\n",
    "\n",
    "        history_df = pd.DataFrame()\n",
    "\n",
    "        building_name = property_details.get('building_name')\n",
    "        availability = property_details.get('building_availability', [])\n",
    "        num_units = property_details.get('number_units', 0)\n",
    "\n",
    "        for unit_id, cur_availability in enumerate(availability):\n",
    "            if not isinstance(cur_availability, dict):\n",
    "                print(f\"Skipping invalid unit data at index {unit_id}: {type(cur_availability)}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                unit_name = cur_availability.get('unit_name')\n",
    "                unit_group = f\"{cur_availability.get('bed', 0)}x{cur_availability.get('bath', 0)}\"\n",
    "\n",
    "                half_baths = cur_availability.get('partial_bath', 0)\n",
    "                if half_baths == 1:\n",
    "                    unit_group += \".5\"\n",
    "\n",
    "                sqft = cur_availability.get('sqft')\n",
    "\n",
    "                for pricing_id, cur_history in enumerate(cur_availability.get('history', [])):\n",
    "                    if not isinstance(cur_history, dict):\n",
    "                        print(f\"Skipping invalid history data at index {pricing_id}: {type(cur_history)}\")\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        effective_price = cur_history.get('effective_price')\n",
    "                        from_date = cur_history.get('from_date')\n",
    "                        to_date = cur_history.get('to_date')\n",
    "\n",
    "                        cur_history_df = pd.DataFrame(\n",
    "                            {\"building_name\": building_name,\n",
    "                             \"unit_name\": unit_name,\n",
    "                             \"unit_group\": unit_group,\n",
    "                             \"sqft\": sqft,\n",
    "                             \"effective_price\": effective_price,\n",
    "                             \"from_date\": from_date,\n",
    "                             \"to_date\": to_date}, index=[0]\n",
    "                        )\n",
    "\n",
    "                        history_df = pd.concat([history_df, cur_history_df])\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing history at index {pricing_id}: {e}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing unit at index {unit_id}: {e}\")\n",
    "\n",
    "        # Convert dates and handle invalid dates\n",
    "        history_df[\"from_date\"] = pd.to_datetime(history_df[\"from_date\"], errors='coerce')\n",
    "        history_df[\"to_date\"] = pd.to_datetime(history_df[\"to_date\"], errors='coerce')\n",
    "\n",
    "        # Sort and calculate leased rate\n",
    "        history_df.sort_values(by=[\"unit_name\", \"from_date\"], inplace=True)\n",
    "        history_df[\"next_from_date\"] = history_df.groupby(\"unit_name\")[\"from_date\"].shift(-1)\n",
    "        history_df[\"leased_rate\"] = (history_df[\"to_date\"] + pd.Timedelta(days=1) < history_df[\"next_from_date\"]) | (history_df['next_from_date'].isna())\n",
    "\n",
    "        # Expand rows for each date in range\n",
    "        expanded_history = []\n",
    "        for _, row in history_df.iterrows():\n",
    "            try:\n",
    "                date_range = pd.date_range(row[\"from_date\"], row[\"to_date\"])\n",
    "                for single_date in date_range:\n",
    "                    expanded_history.append({\n",
    "                        \"building_name\": row[\"building_name\"],\n",
    "                        \"unit_name\": row[\"unit_name\"],\n",
    "                        \"unit_group\": row[\"unit_group\"],\n",
    "                        \"sqft\": row['sqft'],\n",
    "                        \"effective_price\": row[\"effective_price\"],\n",
    "                        \"date\": single_date.strftime(\"%m/%d/%Y\"),\n",
    "                        \"leased_rate\": row[\"leased_rate\"] if single_date == row[\"to_date\"] else False\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error expanding history for row {row['unit_name']}: {e}\")\n",
    "\n",
    "        # Create new DataFrame\n",
    "        expanded_history_df = pd.DataFrame(expanded_history)\n",
    "\n",
    "        return expanded_history_df, num_units\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing property details: {e}\")\n",
    "        return pd.DataFrame(), 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_leased(history_df, num_units):\n",
    "    history_df = history_df.copy()\n",
    "    history_df['date'] = pd.to_datetime(history_df['date'])\n",
    "    \n",
    "    building = history_df['building_name'].unique()[0]\n",
    "    \n",
    "    first_date = history_df['date'].min()\n",
    "    last_date = history_df['date'].max()\n",
    "    date_range = pd.date_range(first_date, last_date, freq='MS')\n",
    "\n",
    "    net_leased_df = pd.DataFrame()\n",
    "    \n",
    "    for date in date_range:\n",
    "        num_vacancies = len(history_df[history_df['date'] == date])\n",
    "\n",
    "        vacancy_rate = num_vacancies / num_units\n",
    "\n",
    "        net_leased_df = pd.concat([net_leased_df, pd.DataFrame({\"property\": building, \"date\": date, \"net_leased\": 1 - vacancy_rate}, index=[0])])\n",
    "\n",
    "    \n",
    "    return net_leased_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comp_net_leased(property):\n",
    "    lat, lon = get_lat_lon(property=property)\n",
    "\n",
    "    property_data = fetch_property_data(property=property, lat=lat, lon=lon)\n",
    "\n",
    "    comps = get_comps(property=property)\n",
    "\n",
    "    property_id = property_data[0].get(\"id\")\n",
    "    property_details = fetch_property_details(property_id)\n",
    "\n",
    "    print(f\"Getting history for {property}...\")\n",
    "\n",
    "    history_df, num_units = get_unit_history(property_details)\n",
    "\n",
    "    net_leased_df = get_net_leased(history_df, num_units)\n",
    "\n",
    "    for i in range(len(comps)):\n",
    "        building_name = comps['building_name'][i]\n",
    "        zip_code = comps['zip_code'][i]\n",
    "\n",
    "        print(f\"Getting net leased for {building_name}...\")\n",
    "\n",
    "        property_data = fetch_property_data(property=building_name, zip_code=zip_code)\n",
    "\n",
    "        property_id = property_data[0].get(\"id\")\n",
    "\n",
    "        property_details = fetch_property_details(property_id=property_id)\n",
    "\n",
    "        history_df, num_units = get_unit_history(property_details=property_details)\n",
    "\n",
    "        net_leased_df = pd.concat([net_leased_df, get_net_leased(history_df=history_df, num_units=num_units)])\n",
    "\n",
    "    net_leased_df = net_leased_df[net_leased_df['date'] >= '2024-01-01']\n",
    "\n",
    "    net_leased_df['year_month'] = net_leased_df['date'].dt.to_period('M')\n",
    "\n",
    "    net_leased_df.to_csv(f\"data/{property} Comps Net Leased.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_rates(unit_history, building_name):\n",
    "    signed_leases = unit_history[unit_history['leased_rate'] == True]\n",
    "\n",
    "    # Convert 'date' to datetime and extract year and month\n",
    "    signed_leases['date'] = pd.to_datetime(signed_leases['date'])\n",
    "    signed_leases['year_month'] = signed_leases['date'].dt.to_period('M')\n",
    "\n",
    "    rolling_rates = pd.DataFrame()\n",
    "\n",
    "    for i in sorted(signed_leases['year_month'].unique()):\n",
    "\n",
    "        applicable_leases = (\n",
    "            signed_leases[\n",
    "                (signed_leases['year_month'] <= i) &\n",
    "                (signed_leases['date'] >= '2024-01-01')\n",
    "            ]\n",
    "            .dropna(subset=['effective_price'])\n",
    "            .groupby(\"unit_name\", as_index=False)\n",
    "            .last()\n",
    "        )\n",
    "\n",
    "        cur_rolling_rates = pd.DataFrame()  # Initialize as empty DataFrame\n",
    "\n",
    "        if not applicable_leases.empty:\n",
    "            sqft_sum = applicable_leases['sqft'].sum()\n",
    "            avg_rent_per_sqft = applicable_leases['effective_price'].sum() / sqft_sum if sqft_sum > 0 else None\n",
    "\n",
    "            cur_rolling_rates = pd.DataFrame({\n",
    "                'building_name': [building_name],\n",
    "                'year_month': [i],\n",
    "                'avg_rent_roll': [applicable_leases['effective_price'].mean()],\n",
    "                'avg_rent_per_sqft': [avg_rent_per_sqft]\n",
    "            })\n",
    "\n",
    "        if not cur_rolling_rates.empty:\n",
    "            rolling_rates = pd.concat([rolling_rates, cur_rolling_rates], ignore_index=True)\n",
    "\n",
    "    rolling_rates['building_name'] = building_name\n",
    "\n",
    "    rolling_rates = rolling_rates[['building_name', 'year_month', 'avg_rent_roll', 'avg_rent_per_sqft']]\n",
    "\n",
    "    return rolling_rates.sort_values(by=\"year_month\", ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comp_rolling_rates(property):\n",
    "    comps = get_comps(property)  # Fetch comps for the reference property\n",
    "\n",
    "    rolling_rates_df = pd.DataFrame()  # Initialize an empty DataFrame for rate data\n",
    "\n",
    "    # Iterate through each comp property and fetch their rate data\n",
    "    for i in range(len(comps)):\n",
    "        building_name = comps['building_name'][i]\n",
    "        zip_code = comps['zip_code'][i]\n",
    "\n",
    "        print(f\"Getting rates for {building_name}...\")\n",
    "\n",
    "        try:\n",
    "            # Fetch property data with latitude and longitude\n",
    "            property_data = fetch_property_data(building_name, zip_code=zip_code)\n",
    "            \n",
    "            # If fetch_property_data fails, property_data will be None\n",
    "            if property_data is None:\n",
    "                print(f\"Failed to fetch property data for {building_name}\")\n",
    "                continue  # Skip to the next property\n",
    "\n",
    "            # Extract property ID\n",
    "            property_id = property_data[0].get(\"id\")\n",
    "\n",
    "            # Fetch property details\n",
    "            property_details = fetch_property_details(property_id)\n",
    "\n",
    "            unit_history, num_units = get_unit_history(property_details)\n",
    "\n",
    "            cur_rolling_rates = get_rolling_rates(unit_history, building_name)\n",
    "\n",
    "            rolling_rates_df = pd.concat([rolling_rates_df, cur_rolling_rates])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting rates for {building_name}: {e}\")\n",
    "            continue  # Skip to the next property in case of error\n",
    "\n",
    "    # Fetch availability for the reference building\n",
    "    building_name = property\n",
    "    lat, lon = get_lat_lon(property)\n",
    "\n",
    "    print(f\"Getting rates for {building_name}...\\n\")\n",
    "\n",
    "    try:\n",
    "        # Fetch property data for the reference property with lat, lon\n",
    "        property_data = fetch_property_data(building_name, lat=lat, lon=lon)\n",
    "\n",
    "        if property_data is None:\n",
    "            print(f\"Failed to fetch property data for {building_name}\")\n",
    "            return rolling_rates_df  # Return the current DataFrame even if the fetch failed\n",
    "\n",
    "        property_id = property_data[0].get(\"id\")\n",
    "        property_details = fetch_property_details(property_id)\n",
    "\n",
    "        unit_history, num_units = get_unit_history(property_details)\n",
    "\n",
    "        cur_rolling_rates = get_rolling_rates(unit_history, building_name)\n",
    "\n",
    "        rolling_rates_df = pd.concat([rolling_rates_df, cur_rolling_rates])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting details for reference property {building_name}: {e}\")\n",
    "        print(f\"Lat: {lat}, Lon: {lon}\\n\")\n",
    "\n",
    "    rolling_rates_df.to_csv(f\"data/{property} Comps Rolling Rates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unit_mix(history_df):\n",
    "\n",
    "    unit_mix = history_df.groupby('unit_group').agg(\n",
    "        average_sqft=('sqft', 'mean'),\n",
    "        count=('unit_name', 'nunique'),\n",
    "    ).reset_index()\n",
    "\n",
    "    unit_mix['prop'] = unit_mix['count'] / sum(unit_mix['count'])\n",
    "\n",
    "    return(unit_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mproperty\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mCortland Rosslyn\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mget_comp_rolling_rates\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mproperty\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m get_comp_net_leased(\u001b[38;5;28mproperty\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mget_comp_rolling_rates\u001b[39m\u001b[34m(property)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_comp_rolling_rates\u001b[39m(\u001b[38;5;28mproperty\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     comps = \u001b[43mget_comps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mproperty\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Fetch comps for the reference property\u001b[39;00m\n\u001b[32m      4\u001b[39m     rolling_rates_df = pd.DataFrame()  \u001b[38;5;66;03m# Initialize an empty DataFrame for rate data\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Iterate through each comp property and fetch their rate data\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mget_comps\u001b[39m\u001b[34m(property)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Fetch comparables\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m response_data = \u001b[43mfetch_comparables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperty_details\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response_data \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcomparables\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response_data \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response_data[\u001b[33m'\u001b[39m\u001b[33mcomparables\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected response format for comparables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mfetch_comparables\u001b[39m\u001b[34m(property_details)\u001b[39m\n\u001b[32m     63\u001b[39m payload = {\u001b[33m\"\u001b[39m\u001b[33msubject\u001b[39m\u001b[33m\"\u001b[39m: property_details}\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHEADERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     response.raise_for_status()\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyson.king\\Documents\\testing_work\\testing\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyson.king\\Documents\\testing_work\\testing\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyson.king\\Documents\\testing_work\\testing\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyson.king\\Documents\\testing_work\\testing\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyson.king\\Documents\\testing_work\\testing\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyson.king\\Documents\\testing_work\\testing\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyson.king\\Documents\\testing_work\\testing\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyson.king\\Documents\\testing_work\\testing\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.752.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.752.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.752.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.752.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.752.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.752.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "property = \"Cortland Rosslyn\"\n",
    "\n",
    "get_comp_rolling_rates(property)\n",
    "get_comp_net_leased(property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_rates = pd.read_csv(f'data/{property} Comps Rolling Rates.csv')\n",
    "net_leased = pd.read_csv(f'data/{property} Comps Net Leased.csv')\n",
    "\n",
    "metrics = pd.merge(left=rolling_rates, right=net_leased, left_on=['building_name', 'year_month'], right_on=['property', 'year_month'])\n",
    "metrics = metrics[['building_name', 'year_month', 'avg_rent_per_sqft', 'net_leased']]\n",
    "\n",
    "metrics['rev_pasf'] = metrics['avg_rent_per_sqft'] * metrics['net_leased']\n",
    "\n",
    "metrics['rev_pasf_rank'] = metrics.groupby('year_month')['rev_pasf'].rank(method='dense', ascending=False)\n",
    "\n",
    "metrics['t1_rev_pasf_rank'] = metrics.groupby(['building_name'])['rev_pasf_rank'].shift(1)\n",
    "\n",
    "metrics['performance_score'] = metrics.apply(\n",
    "    lambda x: (x['t1_rev_pasf_rank'] - x['rev_pasf_rank']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "metrics.to_csv(f'data/{property} Comp Metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_name</th>\n",
       "      <th>unit_name</th>\n",
       "      <th>unit_group</th>\n",
       "      <th>sqft</th>\n",
       "      <th>effective_price</th>\n",
       "      <th>date</th>\n",
       "      <th>leased_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>1101</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1223</td>\n",
       "      <td>1745</td>\n",
       "      <td>09/13/2024</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>1101</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1223</td>\n",
       "      <td>1745</td>\n",
       "      <td>09/14/2024</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>1101</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1223</td>\n",
       "      <td>1745</td>\n",
       "      <td>09/15/2024</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>1101</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1223</td>\n",
       "      <td>1745</td>\n",
       "      <td>09/16/2024</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>1101</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1223</td>\n",
       "      <td>1745</td>\n",
       "      <td>09/17/2024</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14556</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>6140</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1134</td>\n",
       "      <td>1844</td>\n",
       "      <td>09/03/2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14557</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>6140</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1134</td>\n",
       "      <td>1844</td>\n",
       "      <td>09/04/2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14558</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>6140</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1134</td>\n",
       "      <td>1844</td>\n",
       "      <td>09/05/2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14559</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>6140</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1134</td>\n",
       "      <td>1828</td>\n",
       "      <td>09/06/2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14560</th>\n",
       "      <td>Evergreen Lenox Park</td>\n",
       "      <td>6140</td>\n",
       "      <td>2x2</td>\n",
       "      <td>1134</td>\n",
       "      <td>1828</td>\n",
       "      <td>09/07/2023</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14561 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              building_name unit_name unit_group  sqft  effective_price  \\\n",
       "0      Evergreen Lenox Park      1101        2x2  1223             1745   \n",
       "1      Evergreen Lenox Park      1101        2x2  1223             1745   \n",
       "2      Evergreen Lenox Park      1101        2x2  1223             1745   \n",
       "3      Evergreen Lenox Park      1101        2x2  1223             1745   \n",
       "4      Evergreen Lenox Park      1101        2x2  1223             1745   \n",
       "...                     ...       ...        ...   ...              ...   \n",
       "14556  Evergreen Lenox Park      6140        2x2  1134             1844   \n",
       "14557  Evergreen Lenox Park      6140        2x2  1134             1844   \n",
       "14558  Evergreen Lenox Park      6140        2x2  1134             1844   \n",
       "14559  Evergreen Lenox Park      6140        2x2  1134             1828   \n",
       "14560  Evergreen Lenox Park      6140        2x2  1134             1828   \n",
       "\n",
       "             date  leased_rate  \n",
       "0      09/13/2024        False  \n",
       "1      09/14/2024        False  \n",
       "2      09/15/2024        False  \n",
       "3      09/16/2024        False  \n",
       "4      09/17/2024        False  \n",
       "...           ...          ...  \n",
       "14556  09/03/2023        False  \n",
       "14557  09/04/2023        False  \n",
       "14558  09/05/2023        False  \n",
       "14559  09/06/2023        False  \n",
       "14560  09/07/2023         True  \n",
       "\n",
       "[14561 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = fetch_property_data(\"Evergreen Lenox Park\")[0]['id']\n",
    "details = fetch_property_details(id)\n",
    "history_df, num_units = get_unit_history(details)\n",
    "\n",
    "display(history_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
